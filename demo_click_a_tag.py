#!/usr/bin/env python3
"""
ç‚¹å‡»ç¬¬ä¸€ä¸ªAæ ‡ç­¾åŠŸèƒ½æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç‚¹å‡»ç¬¬ä¸€ä¸ªAæ ‡ç­¾çš„åŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

import config
from screenshot_crawler import ScreenshotCrawler


def demo_click_first_a_tag():
    """æ¼”ç¤ºç‚¹å‡»ç¬¬ä¸€ä¸ªAæ ‡ç­¾åŠŸèƒ½"""
    print("ğŸ”— ç‚¹å‡»ç¬¬ä¸€ä¸ªAæ ‡ç­¾åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)
    print(f"ğŸ“‹ åŠŸèƒ½è¯´æ˜:")
    print(f"   ğŸ¯ è‡ªåŠ¨æŸ¥æ‰¾é¡µé¢ä¸­ç¬¬ä¸€ä¸ªå¯ç‚¹å‡»çš„Aæ ‡ç­¾")
    print(f"   ğŸ” æ™ºèƒ½è¿‡æ»¤éšè—å’Œæ— æ•ˆçš„Aæ ‡ç­¾")
    print(f"   ğŸ“Š æ˜¾ç¤ºAæ ‡ç­¾çš„è¯¦ç»†ä¿¡æ¯")
    print(f"   ğŸ–±ï¸  è‡ªåŠ¨ç‚¹å‡»æ‰¾åˆ°çš„Aæ ‡ç­¾")
    print()
    
    # è·å–ç”¨æˆ·è¾“å…¥
    url = input(f"è¯·è¾“å…¥æµ‹è¯•URL (é»˜è®¤: {config.TARGET_URL}): ").strip()
    if not url:
        url = config.TARGET_URL
    
    print(f"\nğŸ“‹ æµ‹è¯•é…ç½®:")
    print(f"   ğŸŒ ç›®æ ‡URL: {url}")
    print()
    
    confirm = input("æ˜¯å¦å¼€å§‹æµ‹è¯•ç‚¹å‡»ç¬¬ä¸€ä¸ªAæ ‡ç­¾ï¼Ÿ(y/N): ").strip().lower()
    if confirm not in ['y', 'yes']:
        print("âŒ æµ‹è¯•å·²å–æ¶ˆ")
        return 0
    
    try:
        print("\nğŸ¬ å¼€å§‹æµ‹è¯•...")
        
        with ScreenshotCrawler() as crawler:
            # åˆå§‹åŒ–å¹¶è®¿é—®é¡µé¢
            crawler._initialize_browser()
            crawler._navigate_to_url(url)
            
            print(f"\nğŸ”— æµ‹è¯•ç‚¹å‡»ç¬¬ä¸€ä¸ªAæ ‡ç­¾åŠŸèƒ½...")
            
            # ç‚¹å‡»ç¬¬ä¸€ä¸ªAæ ‡ç­¾
            success = crawler.click_first_a_tag()
            
            if success:
                print(f"\nğŸ‰ æµ‹è¯•æˆåŠŸ!")
                print(f"âœ… ç¬¬ä¸€ä¸ªAæ ‡ç­¾å·²è¢«æˆåŠŸç‚¹å‡»")
                
                # ç­‰å¾…é¡µé¢å“åº”
                import time
                print(f"â° ç­‰å¾…é¡µé¢å“åº”...")
                time.sleep(3)
                
                # å¯é€‰ï¼šæˆªå›¾æŸ¥çœ‹ç»“æœ
                save_screenshot = input("æ˜¯å¦æˆªå›¾æŸ¥çœ‹ç»“æœï¼Ÿ(y/N): ").strip().lower()
                if save_screenshot in ['y', 'yes']:
                    screenshot_path = crawler._take_screenshot()
                    print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
                    
            else:
                print(f"\nâš ï¸  æµ‹è¯•å¤±è´¥")
                print(f"âŒ æœªèƒ½æ‰¾åˆ°æˆ–ç‚¹å‡»ç¬¬ä¸€ä¸ªAæ ‡ç­¾")
                print(f"ğŸ’¡ å¯èƒ½åŸå› :")
                print(f"   - é¡µé¢ä¸­æ²¡æœ‰å¯ç‚¹å‡»çš„Aæ ‡ç­¾")
                print(f"   - Aæ ‡ç­¾è¢«éšè—æˆ–ç¦ç”¨")
                print(f"   - é¡µé¢è¿˜åœ¨åŠ è½½ä¸­")
                
    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 0
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(demo_click_first_a_tag()) 